{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import uproot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uproot\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import awkward as ak\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, mean_squared_error, roc_curve, auc\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprepared data in ..\\data\\ZMUMU_EGZ_extended_np_pd is missing, preparing and saving here\n"
     ]
    }
   ],
   "source": [
    "test_size=0.2\n",
    "accept_data_filename=\"l1calo_hist_EGZ_extended.root\"\n",
    "reject_data_filename=\"l1calo_hist_ZMUMU_extended.root\"\n",
    "data_subdir=\"ZMUMU_EGZ_extended_np_pd\"\n",
    "\n",
    "save_path = os.path.join(os.path.pardir, \"data\", data_subdir)\n",
    "if os.path.exists(os.path.join(save_path,\"np_data.npz\")) and os.path.exists(os.path.join(save_path,\"input_df.parquet\")):\n",
    "    print(f\"found preprepared data in {save_path}\")\n",
    "    np_data = np.load(os.path.join(save_path,\"np_data.npz\"))\n",
    "    input_np, labels_np = np_data[\"input_np\"], np_data[\"labels_np\"]\n",
    "    input_df = pd.read_parquet(os.path.join(save_path,\"input_df.parquet\"))\n",
    "\n",
    "\n",
    "else:\n",
    "    print(f\"preprepared data in {save_path} is missing, preparing and saving here\")\n",
    "    accept_data_path= os.path.join(os.path.pardir, \"data\", accept_data_filename)\n",
    "    reject_data_path= os.path.join(os.path.pardir, \"data\", reject_data_filename)\n",
    "    DFs = import_data_files([accept_data_path, reject_data_path])\n",
    "\n",
    "    accepted_numpy = ak.to_numpy(DFs[0]['SuperCell_ET'])\n",
    "    rejected_numpy = ak.to_numpy(DFs[1]['SuperCell_ET'])\n",
    "    accepted_labels = np.ones(accepted_numpy.shape[0])\n",
    "    rejected_labels = np.zeros(rejected_numpy.shape[0])\n",
    "\n",
    "    accepted_df = pd.DataFrame({'offline_ele_pt': DFs[0]['offline_ele_pt'],'Label': 1})\n",
    "    rejected_df = pd.DataFrame({'offline_ele_pt': DFs[1]['offline_ele_pt'],'Label': 0})\n",
    "\n",
    "    input_np = np.concatenate((accepted_numpy, rejected_numpy), axis=0)\n",
    "    input_df = pd.concat([accepted_df,rejected_df]).reset_index(drop=True)\n",
    "    labels_np = np.concatenate((accepted_labels, rejected_labels), axis=0)\n",
    "\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.mkdir(save_path)\n",
    "    np.savez(os.path.join(save_path,\"np_data.npz\"), input_np=input_np,labels_np=labels_np)\n",
    "    input_df.to_parquet(os.path.join(save_path,\"input_df.parquet\"), index=False)\n",
    "\n",
    "X_train, X_test, pd_passthrough_train, pd_passthrough_test, y_train, y_test = train_test_split(input_np, input_df, labels_np, test_size=test_size, random_state=42)\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
