{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import all_estimators\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from utilities import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from inspect import signature\n",
    "import csv\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found preprepared data in ..\\data\\ZMUMU_EGZ_extended_iso_vars\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, pd_passthrough_train, pd_passthrough_test = prepare_data(data_subdir=\"ZMUMU_EGZ_extended_iso_vars\", format_mode=\"iso_vars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported 42 binary classifiers:\n",
      "['AdaBoostClassifier', 'BaggingClassifier', 'BernoulliNB', 'CalibratedClassifierCV', 'CategoricalNB', 'ClassifierChain', 'ComplementNB', 'DecisionTreeClassifier', 'DummyClassifier', 'ExtraTreeClassifier', 'ExtraTreesClassifier', 'FixedThresholdClassifier', 'GaussianNB', 'GaussianProcessClassifier', 'GradientBoostingClassifier', 'HistGradientBoostingClassifier', 'KNeighborsClassifier', 'LabelPropagation', 'LabelSpreading', 'LinearDiscriminantAnalysis', 'LinearSVC', 'LogisticRegression', 'LogisticRegressionCV', 'MLPClassifier', 'MultiOutputClassifier', 'MultinomialNB', 'NearestCentroid', 'NuSVC', 'OneVsOneClassifier', 'OneVsRestClassifier', 'OutputCodeClassifier', 'PassiveAggressiveClassifier', 'Perceptron', 'QuadraticDiscriminantAnalysis', 'RadiusNeighborsClassifier', 'RandomForestClassifier', 'RidgeClassifier', 'RidgeClassifierCV', 'SGDClassifier', 'SVC', 'TunedThresholdClassifierCV', 'VotingClassifier']\n"
     ]
    }
   ],
   "source": [
    "all_estimators_list = all_estimators(type_filter=\"classifier\")\n",
    "\n",
    "binary_classifiers = {}\n",
    "default_base_estimator = LogisticRegression()\n",
    "\n",
    "for name, Classifier in all_estimators_list:\n",
    "    try:\n",
    "        # Handle meta-estimators requiring base estimators or parameters\n",
    "        if name in [\n",
    "            \"ClassifierChain\",\n",
    "            \"FixedThresholdClassifier\",\n",
    "            \"MultiOutputClassifier\",\n",
    "            \"OneVsOneClassifier\",\n",
    "            \"OneVsRestClassifier\",\n",
    "            \"OutputCodeClassifier\",\n",
    "            \"StackingClassifier\",\n",
    "            \"TunedThresholdClassifierCV\",\n",
    "            \"VotingClassifier\",\n",
    "        ]:\n",
    "            if \"ClassifierChain\" == name:\n",
    "                clf = Classifier(base_estimator=default_base_estimator)\n",
    "            elif name in [\n",
    "                \"MultiOutputClassifier\",\n",
    "                \"OneVsOneClassifier\",\n",
    "                \"OneVsRestClassifier\",\n",
    "                \"OutputCodeClassifier\",\n",
    "                \"FixedThresholdClassifier\",\n",
    "                \"TunedThresholdClassifierCV\",\n",
    "            ]:\n",
    "                clf = Classifier(estimator=default_base_estimator)\n",
    "            elif name == \"StackingClassifier\":\n",
    "                clf = Classifier(estimators=[(\"lr\", LogisticRegression())])\n",
    "            elif name == \"VotingClassifier\":\n",
    "                clf = Classifier(estimators=[(\"lr\", LogisticRegression())])\n",
    "        else:\n",
    "            # Instantiate directly for non-meta classifiers\n",
    "            clf = Classifier()\n",
    "\n",
    "        if hasattr(clf, \"predict\"):  # Check for predict method\n",
    "            binary_classifiers[name] = Classifier\n",
    "            globals()[name] = Classifier  # Dynamically add to global namespace\n",
    "    except Exception as e:\n",
    "        print(f\"Could not import {name}: {e}\")\n",
    "\n",
    "# Verify imported classifiers\n",
    "print(f\"Imported {len(binary_classifiers)} binary classifiers:\")\n",
    "print(list(binary_classifiers.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tymch\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of AdaBoostClassifier\n",
      "Accuracy: 0.9568\n",
      "Confusion Matrix:\n",
      " [[27334  1276]\n",
      " [  718 16854]]\n",
      "Mean Squared Error: 0.0432\n",
      "\n",
      "Evaluation of BaggingClassifier\n",
      "Accuracy: 0.9571\n",
      "Confusion Matrix:\n",
      " [[27453  1157]\n",
      " [  823 16749]]\n",
      "Mean Squared Error: 0.0429\n",
      "\n",
      "Evaluation of BernoulliNB\n",
      "Accuracy: 0.7140\n",
      "Confusion Matrix:\n",
      " [[20795  7815]\n",
      " [ 5394 12178]]\n",
      "Mean Squared Error: 0.2860\n",
      "\n",
      "Evaluation of CalibratedClassifierCV\n",
      "Accuracy: 0.9487\n",
      "Confusion Matrix:\n",
      " [[27195  1415]\n",
      " [  953 16619]]\n",
      "Mean Squared Error: 0.0513\n",
      "\n",
      "Evaluation of CategoricalNB\n",
      "Accuracy: 0.9453\n",
      "Confusion Matrix:\n",
      " [[27018  1592]\n",
      " [  936 16636]]\n",
      "Mean Squared Error: 0.0547\n",
      "\n",
      "Could not evaluate ClassifierChain: tuple index out of range\n",
      "\n",
      "Evaluation of ComplementNB\n",
      "Accuracy: 0.7485\n",
      "Confusion Matrix:\n",
      " [[17188 11422]\n",
      " [  195 17377]]\n",
      "Mean Squared Error: 0.2515\n",
      "\n",
      "Evaluation of DecisionTreeClassifier\n",
      "Accuracy: 0.9421\n",
      "Confusion Matrix:\n",
      " [[27249  1361]\n",
      " [ 1314 16258]]\n",
      "Mean Squared Error: 0.0579\n",
      "\n",
      "Evaluation of DummyClassifier\n",
      "Accuracy: 0.6195\n",
      "Confusion Matrix:\n",
      " [[28610     0]\n",
      " [17572     0]]\n",
      "Mean Squared Error: 0.3805\n",
      "\n",
      "Evaluation of ExtraTreeClassifier\n",
      "Accuracy: 0.9389\n",
      "Confusion Matrix:\n",
      " [[27147  1463]\n",
      " [ 1361 16211]]\n",
      "Mean Squared Error: 0.0611\n",
      "\n",
      "Evaluation of ExtraTreesClassifier\n",
      "Accuracy: 0.9612\n",
      "Confusion Matrix:\n",
      " [[27426  1184]\n",
      " [  607 16965]]\n",
      "Mean Squared Error: 0.0388\n",
      "\n",
      "Evaluation of FixedThresholdClassifier\n",
      "Accuracy: 0.9497\n",
      "Confusion Matrix:\n",
      " [[27189  1421]\n",
      " [  902 16670]]\n",
      "Mean Squared Error: 0.0503\n",
      "\n",
      "Evaluation of GaussianNB\n",
      "Accuracy: 0.9256\n",
      "Confusion Matrix:\n",
      " [[25765  2845]\n",
      " [  590 16982]]\n",
      "Mean Squared Error: 0.0744\n",
      "\n",
      "Could not evaluate GaussianProcessClassifier: Unable to allocate 254. GiB for an array with shape (184728, 184728) and data type float64\n",
      "\n",
      "Evaluation of GradientBoostingClassifier\n",
      "Accuracy: 0.9612\n",
      "Confusion Matrix:\n",
      " [[27408  1202]\n",
      " [  592 16980]]\n",
      "Mean Squared Error: 0.0388\n",
      "\n",
      "Evaluation of HistGradientBoostingClassifier\n",
      "Accuracy: 0.9624\n",
      "Confusion Matrix:\n",
      " [[27365  1245]\n",
      " [  492 17080]]\n",
      "Mean Squared Error: 0.0376\n",
      "\n",
      "Evaluation of KNeighborsClassifier\n",
      "Accuracy: 0.9576\n",
      "Confusion Matrix:\n",
      " [[27180  1430]\n",
      " [  526 17046]]\n",
      "Mean Squared Error: 0.0424\n",
      "\n",
      "Could not evaluate LabelPropagation: Unable to allocate 127. GiB for an array with shape (184728, 184728) and data type float32\n",
      "\n",
      "Could not evaluate LabelSpreading: Unable to allocate 127. GiB for an array with shape (184728, 184728) and data type float32\n",
      "\n",
      "Evaluation of LinearDiscriminantAnalysis\n",
      "Accuracy: 0.9025\n",
      "Confusion Matrix:\n",
      " [[26376  2234]\n",
      " [ 2270 15302]]\n",
      "Mean Squared Error: 0.0975\n",
      "\n",
      "Evaluation of LinearSVC\n",
      "Accuracy: 0.9487\n",
      "Confusion Matrix:\n",
      " [[27220  1390]\n",
      " [  979 16593]]\n",
      "Mean Squared Error: 0.0513\n",
      "\n",
      "Evaluation of LogisticRegression\n",
      "Accuracy: 0.9497\n",
      "Confusion Matrix:\n",
      " [[27189  1421]\n",
      " [  902 16670]]\n",
      "Mean Squared Error: 0.0503\n",
      "\n",
      "Evaluation of LogisticRegressionCV\n",
      "Accuracy: 0.9505\n",
      "Confusion Matrix:\n",
      " [[27169  1441]\n",
      " [  845 16727]]\n",
      "Mean Squared Error: 0.0495\n",
      "\n",
      "Evaluation of MLPClassifier\n",
      "Accuracy: 0.9618\n",
      "Confusion Matrix:\n",
      " [[27197  1413]\n",
      " [  349 17223]]\n",
      "Mean Squared Error: 0.0382\n",
      "\n",
      "Could not evaluate MultiOutputClassifier: y must have at least two dimensions for multi-output regression but has only one.\n",
      "\n",
      "Evaluation of MultinomialNB\n",
      "Accuracy: 0.7584\n",
      "Confusion Matrix:\n",
      " [[17662 10948]\n",
      " [  210 17362]]\n",
      "Mean Squared Error: 0.2416\n",
      "\n",
      "Evaluation of NearestCentroid\n",
      "Accuracy: 0.8560\n",
      "Confusion Matrix:\n",
      " [[24211  4399]\n",
      " [ 2253 15319]]\n",
      "Mean Squared Error: 0.1440\n",
      "\n",
      "Evaluation of NuSVC\n",
      "Accuracy: 0.9057\n",
      "Confusion Matrix:\n",
      " [[25580  3030]\n",
      " [ 1326 16246]]\n",
      "Mean Squared Error: 0.0943\n",
      "\n",
      "Evaluation of OneVsOneClassifier\n",
      "Accuracy: 0.9497\n",
      "Confusion Matrix:\n",
      " [[27189  1421]\n",
      " [  902 16670]]\n",
      "Mean Squared Error: 0.0503\n",
      "\n",
      "Evaluation of OneVsRestClassifier\n",
      "Accuracy: 0.9497\n",
      "Confusion Matrix:\n",
      " [[27189  1421]\n",
      " [  902 16670]]\n",
      "Mean Squared Error: 0.0503\n",
      "\n",
      "Evaluation of OutputCodeClassifier\n",
      "Accuracy: 0.9497\n",
      "Confusion Matrix:\n",
      " [[27189  1421]\n",
      " [  902 16670]]\n",
      "Mean Squared Error: 0.0503\n",
      "\n",
      "Evaluation of PassiveAggressiveClassifier\n",
      "Accuracy: 0.9299\n",
      "Confusion Matrix:\n",
      " [[25573  3037]\n",
      " [  199 17373]]\n",
      "Mean Squared Error: 0.0701\n",
      "\n",
      "Evaluation of Perceptron\n",
      "Accuracy: 0.9354\n",
      "Confusion Matrix:\n",
      " [[27448  1162]\n",
      " [ 1821 15751]]\n",
      "Mean Squared Error: 0.0646\n",
      "\n",
      "Evaluation of QuadraticDiscriminantAnalysis\n",
      "Accuracy: 0.7774\n",
      "Confusion Matrix:\n",
      " [[18843  9767]\n",
      " [  513 17059]]\n",
      "Mean Squared Error: 0.2226\n",
      "\n",
      "Could not evaluate RadiusNeighborsClassifier: No neighbors found for test samples array([    2,    10,    14, ..., 46176, 46178, 46179]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "\n",
      "Evaluation of RandomForestClassifier\n",
      "Accuracy: 0.9618\n",
      "Confusion Matrix:\n",
      " [[27414  1196]\n",
      " [  568 17004]]\n",
      "Mean Squared Error: 0.0382\n",
      "\n",
      "Evaluation of RidgeClassifier\n",
      "Accuracy: 0.9022\n",
      "Confusion Matrix:\n",
      " [[26403  2207]\n",
      " [ 2308 15264]]\n",
      "Mean Squared Error: 0.0978\n",
      "\n",
      "Evaluation of RidgeClassifierCV\n",
      "Accuracy: 0.9022\n",
      "Confusion Matrix:\n",
      " [[26403  2207]\n",
      " [ 2308 15264]]\n",
      "Mean Squared Error: 0.0978\n",
      "\n",
      "Evaluation of SGDClassifier\n",
      "Accuracy: 0.9496\n",
      "Confusion Matrix:\n",
      " [[26791  1819]\n",
      " [  509 17063]]\n",
      "Mean Squared Error: 0.0504\n",
      "\n",
      "Evaluation of SVC\n",
      "Accuracy: 0.9607\n",
      "Confusion Matrix:\n",
      " [[27243  1367]\n",
      " [  448 17124]]\n",
      "Mean Squared Error: 0.0393\n",
      "\n",
      "Evaluation of TunedThresholdClassifierCV\n",
      "Accuracy: 0.9484\n",
      "Confusion Matrix:\n",
      " [[26624  1986]\n",
      " [  398 17174]]\n",
      "Mean Squared Error: 0.0516\n",
      "\n",
      "Evaluation of VotingClassifier\n",
      "Accuracy: 0.9541\n",
      "Confusion Matrix:\n",
      " [[27594  1016]\n",
      " [ 1102 16470]]\n",
      "Mean Squared Error: 0.0459\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# binary_classifiers_short = dict(list(binary_classifiers.items())[:10])\n",
    "results = []\n",
    "for name, Classifier in binary_classifiers.items():\n",
    "    try:\n",
    "        if name in [\n",
    "            \"ClassifierChain\",\n",
    "            \"FixedThresholdClassifier\",\n",
    "            \"MultiOutputClassifier\",\n",
    "            \"OneVsOneClassifier\",\n",
    "            \"OneVsRestClassifier\",\n",
    "            \"OutputCodeClassifier\",\n",
    "            \"StackingClassifier\",\n",
    "            \"TunedThresholdClassifierCV\",\n",
    "            \"VotingClassifier\",\n",
    "        ]:\n",
    "            if name == \"ClassifierChain\":\n",
    "                clf = Classifier(base_estimator=LogisticRegression())\n",
    "            elif name in [\n",
    "                \"MultiOutputClassifier\",\n",
    "                \"OneVsOneClassifier\",\n",
    "                \"OneVsRestClassifier\",\n",
    "                \"OutputCodeClassifier\",\n",
    "                \"FixedThresholdClassifier\",\n",
    "                \"TunedThresholdClassifierCV\",\n",
    "            ]:\n",
    "                clf = Classifier(estimator=LogisticRegression())\n",
    "            elif name == \"StackingClassifier\":\n",
    "                clf = Classifier(estimators=[(\"lr\", LogisticRegression()), (\"rf\", RandomForestClassifier())])\n",
    "            elif name == \"VotingClassifier\":\n",
    "                clf = Classifier(estimators=[(\"lr\", LogisticRegression()), (\"rf\", RandomForestClassifier())])\n",
    "        else:\n",
    "            # Check if random_state is a parameter and set it if available\n",
    "            params = signature(Classifier).parameters\n",
    "            if \"random_state\" in params:\n",
    "                clf = Classifier(random_state=42)\n",
    "            else:\n",
    "                clf = Classifier()\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "        # Save results\n",
    "        results.append({\n",
    "            \"Classifier\": name,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"MSE\": mse,\n",
    "            \"TN\": tn,\n",
    "            \"FP\": fp,\n",
    "            \"FN\": fn,\n",
    "            \"TP\": tp,\n",
    "        })\n",
    "\n",
    "        evaluate_sklearn_model(y_test, y_pred, show_CR=False, show_MSE=True, model_name=f'{name}')\n",
    "    except Exception as e:\n",
    "        # On error, save classifier name with NULL values\n",
    "        print(f\"Could not evaluate {name}: {e}\\n\")\n",
    "        results.append({\n",
    "            \"Classifier\": name,\n",
    "            \"Accuracy\": \"NULL\",\n",
    "            \"MSE\": \"NULL\",\n",
    "            \"TN\": \"NULL\",\n",
    "            \"FP\": \"NULL\",\n",
    "            \"FN\": \"NULL\",\n",
    "            \"TP\": \"NULL\",\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to sklearn_all_results_iso.csv\n"
     ]
    }
   ],
   "source": [
    "output_file = \"sklearn_all_results_iso.csv\"\n",
    "with open(output_file, mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=[\"Classifier\", \"Accuracy\", \"MSE\", \"TN\", \"FP\", \"FN\", \"TP\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(results)\n",
    "\n",
    "print(f\"Results saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
